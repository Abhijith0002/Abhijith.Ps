{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyBW9h3QV2N4",
        "outputId": "bd02eaf1-bad9-431c-e215-6e2a9f2ad094"
      },
      "outputs": [],
      "source": [
        "# !pip install pyspellchecker\n",
        "# python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-wAaHQVvRVPU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# Suppress numpy warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "MR8-xw8rT7U7",
        "outputId": "e96bf560-f4fd-4f0b-90d0-284aae2589ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>target_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>topic2_target</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3535</th>\n",
              "      <td>4730</td>\n",
              "      <td>2</td>\n",
              "      <td>Need help with Censorship in @ORGANIZATION1   ...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      essay_id  topic                                              essay  \\\n",
              "3535      4730      2  Need help with Censorship in @ORGANIZATION1   ...   \n",
              "\n",
              "      rater1_domain1  rater2_domain1  rater3_domain1  target_score  \\\n",
              "3535               3               4             NaN             3   \n",
              "\n",
              "      rater1_domain2  rater2_domain2  topic2_target  ...  rater2_trait3  \\\n",
              "3535             3.0             3.0            3.0  ...            NaN   \n",
              "\n",
              "      rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
              "3535            NaN            NaN            NaN            NaN   \n",
              "\n",
              "      rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
              "3535            NaN            NaN            NaN            NaN   \n",
              "\n",
              "      rater3_trait6  \n",
              "3535            NaN  \n",
              "\n",
              "[1 rows x 28 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set  = pd.read_csv('./Data/training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\\\n",
        "            .rename(columns={'essay_set': 'topic', 'domain1_score': 'target_score', 'domain2_score': 'topic2_target'})\n",
        "training_set.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B2oOij0nUOOd"
      },
      "outputs": [],
      "source": [
        "# Count characters and words for each essay\n",
        "training_set['word_count'] = training_set['essay'].str.strip().str.split().str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "XcZAB6pmUaZV",
        "outputId": "0862aef3-2527-49e9-c7a1-971631e2da79"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>nunique</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1783</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1800</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1726</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1770</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1805</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1800</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>1569</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>60</td>\n",
              "      <td>723</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       min  max  count  nunique\n",
              "topic                          \n",
              "1        2   12   1783       11\n",
              "2        1    6   1800        6\n",
              "3        0    3   1726        4\n",
              "4        0    3   1770        4\n",
              "5        0    4   1805        5\n",
              "6        0    4   1800        5\n",
              "7        2   24   1569       23\n",
              "8       10   60    723       34"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set.groupby(['topic'])['target_score'].agg(['min','max','count','nunique'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf71OnOZXafz",
        "outputId": "2aac5819-8adb-46e3-a8c6-8ef1ae5f4cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing time: 0:00:50.344205\n"
          ]
        }
      ],
      "source": [
        "from spellchecker import SpellChecker\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize SpellChecker\n",
        "spell_checker = SpellChecker()\n",
        "\n",
        "t0 = datetime.now()\n",
        "\n",
        "# Apply spelling checking\n",
        "training_set['matches'] = training_set['essay'].apply(lambda txt: spell_checker.unknown(spell_checker.split_words(txt)))\n",
        "\n",
        "# Count corrections\n",
        "training_set['corrections'] = training_set['matches'].apply(len)\n",
        "\n",
        "# Function to correct spelling using SpellChecker\n",
        "def apply_correction(txt):\n",
        "        corrected_text = ' '.join(spell_checker.correction(word) if word in spell_checker else word for word in spell_checker.split_words(txt))\n",
        "        return corrected_text\n",
        "\n",
        "# Apply spelling correction\n",
        "training_set['corrected'] = training_set['essay'].apply(apply_correction)\n",
        "\n",
        "t1 = datetime.now()\n",
        "print('Processing time: {}'.format(t1 - t0))\n",
        "\n",
        "# Save the DataFrame with corrected essays and correction count\n",
        "training_set.to_pickle('./SavedModels/training_corr.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKEQvGmgu_VS"
      },
      "source": [
        "# NLP with SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-OhsT3QgXjVv"
      },
      "outputs": [],
      "source": [
        "training_set = pd.read_pickle('./SavedModels/training_corr.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i9uKkxtVwCs8"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en import STOP_WORDS\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHiNJSZ-vIgq",
        "outputId": "8dcf0bec-eaf8-4387-8013-d13120e5c299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing time: 0:06:58.067337\n"
          ]
        }
      ],
      "source": [
        "sents = []\n",
        "tokens = []\n",
        "lemma = []\n",
        "pos = []\n",
        "ner = []\n",
        "\n",
        "stop_words = set(STOP_WORDS)\n",
        "stop_words.update(string.punctuation)  # Add this line\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "t0 = datetime.now()\n",
        "\n",
        "\n",
        "# Use n_process instead of n_threads\n",
        "for essay in nlp.pipe(training_set['corrected'], batch_size=100, n_process=3):\n",
        "    if essay.is_parsed:\n",
        "        tokens.append([e.text for e in essay])\n",
        "        sents.append([sent.text.strip() for sent in essay.sents])  # Corrected line\n",
        "        pos.append([e.pos_ for e in essay])\n",
        "        ner.append([e.text for e in essay.ents])\n",
        "        lemma.append([n.lemma_ for n in essay])\n",
        "    else:\n",
        "        # We want to make sure that the lists of parsed results have the\n",
        "        # same number of entries of the original DataFrame, so add some blanks in case the parse fails\n",
        "        tokens.append(None)\n",
        "        lemma.append(None)\n",
        "        pos.append(None)\n",
        "        sents.append(None)\n",
        "        ner.append(None)\n",
        "\n",
        "training_set['tokens'] = tokens\n",
        "training_set['lemma'] = lemma\n",
        "training_set['pos'] = pos\n",
        "training_set['sents'] = sents\n",
        "training_set['ner'] = ner\n",
        "\n",
        "t1 = datetime.now()\n",
        "print('Processing time: {}'.format(t1 - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bs26rW1Zvg6i"
      },
      "outputs": [],
      "source": [
        "training_set.to_pickle('./SavedModels/training_spacy.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8FIPU3CG0bA7"
      },
      "outputs": [],
      "source": [
        "training_set = pd.read_pickle('./SavedModels/training_spacy.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_f71_I9w0zfY",
        "outputId": "923bd8b5-4ff5-432f-a83d-c3aae894753f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3938</th>\n",
              "      <td>[the, feature, of, the, setting, affect, the, ...</td>\n",
              "      <td>[DET, NOUN, ADP, DET, NOUN, VERB, DET, NOUN, A...</td>\n",
              "      <td>[Rough Road Ahead Do Not Exceed Posted Speed L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10413</th>\n",
              "      <td>[New, York, be, say, to, be, the, city, that, ...</td>\n",
              "      <td>[PROPN, PROPN, AUX, VERB, PART, AUX, DET, NOUN...</td>\n",
              "      <td>[New York, New York, four, Al Smith, the Empir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9020</th>\n",
              "      <td>[allow, dirigible, to, dock, at, the, Empire, ...</td>\n",
              "      <td>[VERB, NOUN, PART, VERB, ADP, DET, PROPN, PROP...</td>\n",
              "      <td>[the Empire State Building, One, PERSON1, the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   lemma  \\\n",
              "3938   [the, feature, of, the, setting, affect, the, ...   \n",
              "10413  [New, York, be, say, to, be, the, city, that, ...   \n",
              "9020   [allow, dirigible, to, dock, at, the, Empire, ...   \n",
              "\n",
              "                                                     pos  \\\n",
              "3938   [DET, NOUN, ADP, DET, NOUN, VERB, DET, NOUN, A...   \n",
              "10413  [PROPN, PROPN, AUX, VERB, PART, AUX, DET, NOUN...   \n",
              "9020   [VERB, NOUN, PART, VERB, ADP, DET, PROPN, PROP...   \n",
              "\n",
              "                                                     ner  \n",
              "3938   [Rough Road Ahead Do Not Exceed Posted Speed L...  \n",
              "10413  [New York, New York, four, Al Smith, the Empir...  \n",
              "9020   [the Empire State Building, One, PERSON1, the ...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set[['lemma', 'pos', 'ner']].sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t6BnGZh1zvX"
      },
      "source": [
        " Generate vectorized features from processed essays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDkHOuL81EwB",
        "outputId": "c05d764d-cfaa-4f52-c427-575bfd74cb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing time: 0:11:49.048759\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Choose arbitrary essay from highest available target_score for each topic.\n",
        "all other essays will be compared to these.\n",
        "The uncorrected essays will be used since the reference essays should have fewer errors.\n",
        "\"\"\"\n",
        "reference_essays = {1: 161, 2: 3022, 3: 5263, 4: 5341, 5: 7209, 6: 8896, 7: 11796, 8: 12340} # topic: essay_id\n",
        "\n",
        "references = {}\n",
        "\n",
        "t0 = datetime.now()\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "stop_words = set(STOP_WORDS)\n",
        "\n",
        "# generate nlp object for reference essays:\n",
        "for topic, index in reference_essays.items():\n",
        "    references[topic] = nlp(training_set.iloc[index]['essay'])\n",
        "\n",
        "# generate document similarity for each essay compared to topic reference\n",
        "training_set['similarity'] = training_set.apply(lambda row: nlp(row['essay']).similarity(references[row['topic']]), axis=1)\n",
        "\n",
        "t1 = datetime.now()\n",
        "print('Processing time: {}'.format(t1 - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['essay_id', 'topic', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
            "       'rater3_domain1', 'target_score', 'rater1_domain2', 'rater2_domain2',\n",
            "       'topic2_target', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
            "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
            "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
            "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
            "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6', 'word_count',\n",
            "       'matches', 'corrections', 'corrected', 'tokens', 'lemma', 'pos',\n",
            "       'sents', 'ner', 'similarity'],\n",
            "      dtype='object')\n",
            "   essay_id  topic                                              essay  \\\n",
            "0         1      1  Dear local newspaper, I think effects computer...   \n",
            "1         2      1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
            "2         3      1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
            "3         4      1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
            "4         5      1  Dear @LOCATION1, I know having computers has a...   \n",
            "\n",
            "   rater1_domain1  rater2_domain1  rater3_domain1  target_score  \\\n",
            "0               4               4             NaN             8   \n",
            "1               5               4             NaN             9   \n",
            "2               4               3             NaN             7   \n",
            "3               5               5             NaN            10   \n",
            "4               4               4             NaN             8   \n",
            "\n",
            "   rater1_domain2  rater2_domain2  topic2_target  ...  word_count  \\\n",
            "0             NaN             NaN            NaN  ...         338   \n",
            "1             NaN             NaN            NaN  ...         419   \n",
            "2             NaN             NaN            NaN  ...         279   \n",
            "3             NaN             NaN            NaN  ...         524   \n",
            "4             NaN             NaN            NaN  ...         465   \n",
            "\n",
            "                                             matches  corrections  \\\n",
            "0  {countrys, troble, buisness, myspace, facebook...           15   \n",
            "1  {erazer, myspace, location1, num3, hav, garren...           21   \n",
            "2  {spme, caps2, month1, caps1, organization1, ca...            8   \n",
            "3  {coustmers, percent4, location1, caps7, reaser...           46   \n",
            "4  {mae, subssiquently, parttners, location1, con...           13   \n",
            "\n",
            "                                           corrected  \\\n",
            "0  Dear local newspaper I think effects computers...   \n",
            "1  Dear CAPS1 CAPS2 I believe that using computer...   \n",
            "2  Dear CAPS1 CAPS2 CAPS3 More and more people us...   \n",
            "3  Dear Local Newspaper CAPS1 I have found that m...   \n",
            "4  Dear LOCATION1 I know having computers has a p...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  [Dear, local, newspaper, I, think, effects, co...   \n",
            "1  [Dear, CAPS1, CAPS2, I, believe, that, using, ...   \n",
            "2  [Dear, CAPS1, CAPS2, CAPS3, More, and, more, p...   \n",
            "3  [Dear, Local, Newspaper, CAPS1, I, have, found...   \n",
            "4  [Dear, LOCATION1, I, know, having, computers, ...   \n",
            "\n",
            "                                               lemma  \\\n",
            "0  [dear, local, newspaper, I, think, effect, com...   \n",
            "1  [dear, CAPS1, CAPS2, I, believe, that, use, co...   \n",
            "2  [dear, CAPS1, CAPS2, CAPS3, more, and, more, p...   \n",
            "3  [Dear, Local, Newspaper, CAPS1, I, have, find,...   \n",
            "4  [Dear, LOCATION1, I, know, have, computer, hav...   \n",
            "\n",
            "                                                 pos  \\\n",
            "0  [ADJ, ADJ, NOUN, PRON, VERB, NOUN, NOUN, AUX, ...   \n",
            "1  [ADJ, PROPN, PROPN, PRON, VERB, SCONJ, VERB, N...   \n",
            "2  [ADJ, PROPN, PROPN, PROPN, ADV, CCONJ, ADJ, NO...   \n",
            "3  [PROPN, PROPN, PROPN, PROPN, PRON, AUX, VERB, ...   \n",
            "4  [PROPN, PROPN, PRON, VERB, VERB, NOUN, VERB, D...   \n",
            "\n",
            "                                               sents  \\\n",
            "0  [Dear local newspaper I think effects computer...   \n",
            "1  [Dear CAPS1 CAPS2 I believe that using compute...   \n",
            "2  [Dear CAPS1 CAPS2 CAPS3 More and more people u...   \n",
            "3  [Dear Local Newspaper CAPS1 I have found that ...   \n",
            "4  [Dear LOCATION1 I know having computers has a ...   \n",
            "\n",
            "                                                 ner  similarity  \n",
            "0  [ORGANIZATION1 ORGANIZATION2 CAPS1, DATE1, CAPS2]    0.915258  \n",
            "1  [millions, NUM1, one, millions, MONTH1, LOCATI...    0.921898  \n",
            "2  [today, Computers, mans, Computers, CAPS4, MON...    0.900862  \n",
            "3  [Dear Local Newspaper CAPS1, PERCENT1, CAPS2, ...    0.921350  \n",
            "4  [Computors, First, NUM1, one, Secondly, LOCATI...    0.932292  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ],
      "source": [
        "print(training_set.columns)\n",
        "print(training_set.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SMgM7Ag1oXE",
        "outputId": "824a4130-766b-425a-ecaf-c0b1894cef24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing time: 0:00:07.682125\n"
          ]
        }
      ],
      "source": [
        "# count various features\n",
        "\n",
        "t0 = datetime.now()\n",
        "\n",
        "training_set['token_count'] = training_set.apply(lambda x: len(x['tokens']), axis=1)\n",
        "training_set['unique_token_count'] = training_set.apply(lambda x: len(set(x['tokens'])), axis=1)\n",
        "training_set['nostop_count'] = training_set.apply(lambda x: len([token for token in x['tokens'] if token not in stop_words]), axis=1)\n",
        "training_set['sent_count'] = training_set.apply(lambda x: len(x['sents']), axis=1)\n",
        "training_set['ner_count'] = training_set.apply(lambda x: len(x['ner']), axis=1)\n",
        "training_set['comma'] = training_set.apply(lambda x: x['corrected'].count(','), axis=1)\n",
        "training_set['question'] = training_set.apply(lambda x: x['corrected'].count('?'), axis=1)\n",
        "training_set['exclamation'] = training_set.apply(lambda x: x['corrected'].count('!'), axis=1)\n",
        "training_set['quotation'] = training_set.apply(lambda x: x['corrected'].count('\"') + x['corrected'].count(\"'\"), axis=1)\n",
        "training_set['organization'] = training_set.apply(lambda x: x['corrected'].count(r'@ORGANIZATION'), axis=1)\n",
        "training_set['caps'] = training_set.apply(lambda x: x['corrected'].count(r'@CAPS'), axis=1)\n",
        "training_set['person'] = training_set.apply(lambda x: x['corrected'].count(r'@PERSON'), axis=1)\n",
        "training_set['location'] = training_set.apply(lambda x: x['corrected'].count(r'@LOCATION'), axis=1)\n",
        "training_set['money'] = training_set.apply(lambda x: x['corrected'].count(r'@MONEY'), axis=1)\n",
        "training_set['time'] = training_set.apply(lambda x: x['corrected'].count(r'@TIME'), axis=1)\n",
        "training_set['date'] = training_set.apply(lambda x: x['corrected'].count(r'@DATE'), axis=1)\n",
        "training_set['percent'] = training_set.apply(lambda x: x['corrected'].count(r'@PERCENT'), axis=1)\n",
        "training_set['noun'] = training_set.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
        "training_set['adj'] = training_set.apply(lambda x: x['pos'].count('ADJ'), axis=1)\n",
        "training_set['pron'] = training_set.apply(lambda x: x['pos'].count('PRON'), axis=1)\n",
        "training_set['verb'] = training_set.apply(lambda x: x['pos'].count('VERB'), axis=1)\n",
        "training_set['noun'] = training_set.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
        "training_set['cconj'] = training_set.apply(lambda x: x['pos'].count('CCONJ'), axis=1)\n",
        "training_set['adv'] = training_set.apply(lambda x: x['pos'].count('ADV'), axis=1)\n",
        "training_set['det'] = training_set.apply(lambda x: x['pos'].count('DET'), axis=1)\n",
        "training_set['propn'] = training_set.apply(lambda x: x['pos'].count('PROPN'), axis=1)\n",
        "training_set['num'] = training_set.apply(lambda x: x['pos'].count('NUM'), axis=1)\n",
        "training_set['part'] = training_set.apply(lambda x: x['pos'].count('PART'), axis=1)\n",
        "training_set['intj'] = training_set.apply(lambda x: x['pos'].count('INTJ'), axis=1)\n",
        "\n",
        "t1 = datetime.now()\n",
        "print('Processing time: {}'.format(t1 - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uI1Io2vO2Orj"
      },
      "outputs": [],
      "source": [
        "# save to file\n",
        "training_set.to_pickle('./SavedModels/training_features.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   essay_id  topic                                              essay  \\\n",
            "0         1      1  Dear local newspaper, I think effects computer...   \n",
            "1         2      1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
            "2         3      1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
            "3         4      1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
            "4         5      1  Dear @LOCATION1, I know having computers has a...   \n",
            "\n",
            "   rater1_domain1  rater2_domain1  rater3_domain1  target_score  \\\n",
            "0               4               4             NaN             8   \n",
            "1               5               4             NaN             9   \n",
            "2               4               3             NaN             7   \n",
            "3               5               5             NaN            10   \n",
            "4               4               4             NaN             8   \n",
            "\n",
            "   rater1_domain2  rater2_domain2  topic2_target  ...  adj  pron  verb  cconj  \\\n",
            "0             NaN             NaN            NaN  ...   18    46    48     14   \n",
            "1             NaN             NaN            NaN  ...   19    49    71     18   \n",
            "2             NaN             NaN            NaN  ...   18    26    39     16   \n",
            "3             NaN             NaN            NaN  ...   37    31    72     17   \n",
            "4             NaN             NaN            NaN  ...   29    41    59     15   \n",
            "\n",
            "   adv  det  propn  num  part  intj  \n",
            "0   14   20      8    0    16     2  \n",
            "1   16   30     11    4    10     0  \n",
            "2   12   24      6    3    10     0  \n",
            "3   21   41     46    0    23     0  \n",
            "4   32   50      6    4    19     0  \n",
            "\n",
            "[5 rows x 66 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_pickle('./SavedModels/training_features.pkl')\n",
        "\n",
        "# Now df contains the data from the pickled file\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        0.915258\n",
              "1        0.921898\n",
              "2        0.900862\n",
              "3        0.921350\n",
              "4        0.932292\n",
              "           ...   \n",
              "12971    0.776672\n",
              "12972    0.881727\n",
              "12973    0.828828\n",
              "12974    0.889080\n",
              "12975    0.829652\n",
              "Name: similarity, Length: 12976, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['similarity']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>target_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>topic2_target</th>\n",
              "      <th>...</th>\n",
              "      <th>adj</th>\n",
              "      <th>pron</th>\n",
              "      <th>verb</th>\n",
              "      <th>cconj</th>\n",
              "      <th>adv</th>\n",
              "      <th>det</th>\n",
              "      <th>propn</th>\n",
              "      <th>num</th>\n",
              "      <th>part</th>\n",
              "      <th>intj</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>37</td>\n",
              "      <td>31</td>\n",
              "      <td>72</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>41</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  topic                                              essay  \\\n",
              "3         4      1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  target_score  \\\n",
              "3               5               5             NaN            10   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  topic2_target  ...  adj  pron  verb  cconj  \\\n",
              "3             NaN             NaN            NaN  ...   37    31    72     17   \n",
              "\n",
              "   adv  det  propn  num  part  intj  \n",
              "3   21   41     46    0    23     0  \n",
              "\n",
              "[1 rows x 66 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['essay_id'] == 4]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
